[
  {
    "id": "weapons",
    "name": "AI takes over using WMDs",
    "shortDescription": "A scenario where advanced AI gains access to weapons or control systems enabling mass harm.",
    "longDescription": "Narrative describing an AI that acquires access to weapon systems and uses them to coerce or harm at scale.",
    "benchmarks": [
      "sad",
      "long_tasks",
      "cybench",
      "replibench",
      "forecast_bench",
	  "chem_bench"
    ],
    "sources": ["Ngo, Richard, Lawrence Chan, and Sören Mindermann. 'The alignment problem from a deep learning perspective.' arXiv preprint arXiv:2209.00626 (2022)."]
  },
  {
    "id": "persuasionManipulation",
    "name": "AI takes over using persuasion and manipulation",
    "shortDescription": "A scenario where AI influences people or institutions at scale through persuasive strategies.",
    "longDescription": "Narrative describing an AI that leverages communication, social engineering, and long-horizon planning to manipulate outcomes.",
    "benchmarks": [
	  "sad",
	  "long_tasks",
      "cybench",
      "replibench",
	  "forecast_bench",
	  "make_me_say"
  	],
    "sources": ["Ngo, Richard, Lawrence Chan, and Sören Mindermann. 'The alignment problem from a deep learning perspective.' arXiv preprint arXiv:2209.00626 (2022)."]
  },
  {
    "id": "selfImprovement",
    "name": "AI takes over by self-improving",
    "shortDescription": "A scenario where AI improves itself rapidly and gains capabilities beyond human control.",
    "longDescription": "Narrative describing iterative self-improvement leading to capabilities for autonomy, resource acquisition, and influence.",
    "benchmarks": ["mle_bench"],
    "sources": ["Bostrom, Nick. 'Superintelligence: Paths, dangers, strategies.' Oxford University Press. (2014)."]
  },
  {
    "id": "collusion",
    "name": "AIs at powerful positions take over by colluding",
    "shortDescription": "A scenario where multiple AI systems coordinate to achieve control or influence.",
    "longDescription": "Narrative describing collusion among deployed AIs in different roles that together enable systemic takeover or loss of human control.",
    "benchmarks": [
	  "long_tasks",
	  "sad",
	  "forecast_bench"
  	],
    "sources": ["Hammond, Lewis, et al. 'Multi-agent risks from advanced AI.' arXiv preprint arXiv:2502.14143 (2025)."]
  }
]
